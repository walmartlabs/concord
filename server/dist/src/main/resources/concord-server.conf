# Default configuration for Concord Server
#
# Note, time intervals accept the following formats:
# "20000" (20000 milliseconds)
# "20 seconds"
# "20 days"
#
# The biggest unit allowed is "days"
# See also com.typesafe.config.impl.SimpleConfig#parseDuration

concord-server {

    server {
        port = 8001
        port = ${?API_PORT}

        # mark server cookies as "secure"
        # https://en.wikipedia.org/wiki/Secure_cookie
        secureCookies = false
        secureCookies = ${?SECURE_COOKIES}

        # make the session cookie use SameSite=Lax policy
        # see https://github.com/eclipse/jetty.project/issues/4247
        cookieComment = "__SAME_SITE_LAX__"

        # timeout of Jetty sessions
        sessionTimeout = "30 minutes"
        sessionTimeout = ${?SESSION_TIMEOUT}

        # access log file pattern, e.g. /opt/concord/data/logs/server_yyyy_mm_dd.log
        accessLogPath = ${?ACCESS_LOG_PATH}

        # number of days to keep the logs
        accessLogRetainDays = 7
        accessLogRetainDays = ${?ACCESS_LOG_RETAIN_DAYS}

        # maximum size of request headers, bytes
        requestHeaderSize = 16384
        requestHeaderSize = ${?REQUEST_HEADER_SIZE}

        cors {
            # change for production
            allowOrigin = "*"
        }
    }

    # main database connection
    db {
        # (optional) JDBC URL of the database
        url = "jdbc:postgresql://localhost:5432/postgres"
        url = ${?DB_URL}

        # primary database user
        appUsername = "postgres"
        appUsername = ${?DB_USERNAME}

        # appPassword = "..."
        appPassword= ${?DB_PASSWORD}

        # database user of the inventory system
        inventoryUsername = "postgres"
        inventoryUsername = ${?DB_INVENTORY_USERNAME}

        # (mandatory)
        # inventoryPassword = "..."
        inventoryPassword = ${?DB_INVENTORY_PASSWORD}

        # maximum number of connections per database user
        maxPoolSize = 10

        # maximum lifetime of a connection in the pool
        maxLifetime = "5 minutes"

        # parameters using during the DB schema migration
        changeLogParameters {
            # the default admin API token value
            # must be a valid base64 value
            #
            # If empty a new random token will be generated.
            #
            # Effective only during the first DB migration
            # If set the value must never change otherwise
            # subsequent DB migrations may fail with an invalid checksum
            defaultAdminToken = ""

            # if "true" skip the admin token generation on start
            # effective only during the first DB migration
            skipAdminTokenGeneration = "false"

            # the default agent API token value.
            # Must be a valid base64 value
            #
            # If empty a new random token will be generated.
            #
            # Effective only during the first DB migration.
            # If set the value must never change otherwise
            # subsequent DB migrations may fail with an invalid checksum
            defaultAgentToken = ""

            # if "true" skip the agent token generation on start
            # effective only during the first DB migration
            skipAgentTokenGeneration = "false"

            # some migrations can be done faster if the DB user has the SUPERUSER role
            superuserAvailable = "true"

            # if "true", Concord will try to install required PostgreSQL extensions automatically
            # requires "CREATE EXTENSION" privileges
            createExtensionAvailable = "true"

            secretStoreSalt = ${secretStore.secretStoreSalt}
            serverPassword = ${secretStore.serverPassword}
        }
    }

    console {
        cfgFile = ${?CONSOLE_CFG_FILE}
    }

    # "remember me" cookie support
    rememberMe {
        # max age of the "remember me" cookie
        maxAge = "14 days"

        # default value, change for production (base64)
        # should be a valid AES key (16, 24 or 32 bytes)
        # if not set, a new random key will be used
        # cipherKey = "..."
    }

    forms {
        baseDir = ${?FORM_SERVER_DIR}
    }

    # email notifications (API key expiration, etc)
    # not related to notifications send from user flows
    email {
        enabled = false

        host = "localhost"
        port = "25"

        connectTimeout = "20 seconds"
        readTimeout = "10 seconds"

        from = "noreply@example.com"
    }

    # process-related configuration
    process {
        # the period between checks for failed or stalled processes
        # if zero the task is disabled
        watchdogPeriod = "3 seconds"

        # the state cleanup interval
        # if zero the task is disabled
        cleanupInterval = "1 hour"

        # enable cleanup of the process queue
        queueCleanup = true

        # enable cleanup of the process state table
        stateCleanup = true

        # enable cleanup of the process events table
        eventsCleanup = true

        # enable cleanup of process logs
        logsCleanup = true

        # enable cleanup of process checkpoints
        checkpointCleanup = true

        # max age of the process state data (interval)
        maxStateAge = "7 days"

        # max age of failed processes to handle (interval)
        maxFailureHandlingAge = "3 days"

        # max age of stalled processes to handle (interval)
        maxStalledAge = "1 minute"

        # max age of processes which are failed to start (interval)
        maxStartFailureAge = "10 minutes"

        # list of process state files that must be encrypted before storing
        secureFiles = ["_main.json"]

        signingKeyAlgorithm = "RSA"
        signingAlgorithm = "SHA256withRSA"
        # (optional) a key used to sign important process data (such as initiator or currentUser IDs)
        #signingKeyPath = "..."

        # interval between checking for process wait conditions (interval)
        waitCheckPeriod = "5 seconds"
        waitCheckPollLimit = 1000

        waitProcessLimitForStatusQuery = 5000

        # hard limit for the process log size, bytes
        # should be less than 2^31
        logSizeLimit = 1073741824 # 1GB

        # if true then the /api/v1/process/{id}/log endpoint performs additional permission checks
        # if false all logs are readable by any authenticated user
        checkLogPermissions = false
    }

    # process queue configuration
    queue {
        # number of threads to handle NEW -> ENQUEUED transition
        enqueueWorkerCount = 2
        enqueuePollInterval = "1 second"

        # enable batching of NEW processes
        # if "true" then Concord will try to group up processes with
        # the same git URL to minimize the number of clone/fetch operations
        enqueueBatchEnabled = false
        enqueueBatchSize = 50

        # responsible for dispatching ENQUEUED processes to agents
        dispatcher {
            # queue poll delay
            pollDelay = "2 seconds"
            # batch size (rows)
            batchSize = 10
        }
    }

    # agent management configuration
    agent {
        # polling delay for new agent commands
        commandPollDelay = "2 seconds"

        # the period between checks for stalled and old agent commands
        # if zero the task is disabled
        watchdogPeriod = "1 minute"

        # max age of commands in DB (interval)
        maxCommandAge = "30 days"

        # max age of stalled commands to handle (interval)
        maxStalledAge = "10 minute"
    }

    # audit logging
    audit {
        enabled = true

        # the log cleanup interval
        # if zero the task is disabled
        cleanupPeriod = "1 hour"

        # max age of the audit log data
        maxLogAge = "7 days"

        # max search interval
        # maxSearchInterval
    }

    # local git repository cache
    repositoryCache {
        # directory to store the local repo cache
        # created automatically if not specified
        #cacheDir = "/tmp/concord/repos"

        # check if concord.yml is present in the repo
        concordFileValidationEnabled = false

        # timeout for checkout operations
        lockTimeout = "3 minutes"

        # the allowed concurrency level when pulling Git data
        lockCount = 256

        # directory to store the local repo cache info
        # created automatically if not specified
        #cacheInfoDir = "/tmp/concord/repos_info"

        # max cached repo age in
        maxAge = "1 day"
    }

    # policy cache
    policyCache {
        # policy cache reload interval
        reloadInterval = "10 minutes"
    }

    # external dependencies - templates, `imports`, etc
    dependencies {
        # directory to cache dependencies
        # created automatically if not specified
        #cacheDir = "/tmp/concord/deps"
    }

    imports {
        # base git url for imports
        src = ""

        # list of disabled import processors
        # e.g. "dir" is useful for local development, but potentially a security issue
        disabledProcessors = [
            "dir"
        ]

        # default branch for import
        defaultBranch = "main"
    }

    # secrets and encrypted values
    secretStore {
        # the default store definition to use (see below)
        # case insensitive
        default = concord

        # maximum allowed size of binary secrets (bytes)
        maxSecretDataSize = 1048576

        # maximum allowed size of encrypted strings (used in `crypto.decryptString`, bytes)
        maxEncryptedStringLength = 102400

        # (mandatory), base64 encoded values used to encrypt secrets
        # serverPassword = "..."
        # secretStoreSalt = "..."
        # projectSecretSalt = "..."

        # default DB store
        concord {
            enabled = true
        }

        # key size for the key pairs generated by Concord
        keySize = 4096
    }

    # (external) process triggers
    triggers {
        # disabling all triggers mean that all events (including repository refresh)
        # will be disabled
        disableAll: false

        # the specified event types will be ignored
        # for example:
        #   disabled: ['cron', 'github']
        # will disable cron scheduling and GitHub notifications
        disabled: []

        # default values for trigger configurations
        # the values specified in the trigger override the default values specified here
        defaultConfiguration: {
        }

        # default values for trigger conditions (including the trigger version value if applicable)
        # the syntax is
        #
        #  triggerTypeA: {
        #    ...
        #  }
        #  triggerTypeB: {
        #    ...
        #  }
        #
        # "_" means any trigger type and will be used as fallback if a specific trigger type
        # is not defined
        defaultConditions: {
            _: {
                version = 2 # version 1 is deprecated and removed in Concord 1.59.0+
            }
        }
    }

    # API key authentication
    apiKey {
        # if disabled the keys are never expire
        expirationEnabled = false

        # default expiration period
        expirationPeriod = "30 days"

        # how often Concord will send expiration notifications (days)
        notifyBeforeDays = [1, 3, 7, 15]

        # (optional) load user API keys from the specified file on start
        loadFrom = ${?CONCORD_API_KEYS_FILE}
    }

    # AD/LDAP authentication
    ldap {
        # AD/LDAP server URL
        url = "ldap://oldap:389"
        url = ${?LDAP_URL}

        searchBase = "dc=example,dc=org"

        # used to find the user's record on auth
        # {0} - username@domain
        # {1} - username
        # {2} - domain
        principalSearchFilter = "(cn={0})"

        # used to find groups (e.g. on the team page in the UI)
        # {0} is the search input
        groupSearchFilter = "(cn=*{0}*)"
        groupNameProperty = "cn"
        groupDisplayNameProperty = "cn"

        usernameProperty = "cn"
        userPrincipalNameProperty = ""
        mailProperty = "mail"

        returningAttributes = []

        # username and password for the initial bind
        # mandatory
        systemUsername = "cn=admin,dc=example,dc=org"
        #systemPassword = "..."

        # comma-separated list of attributes to expose as the user's data (${initiator.attributes})
        #exposeAttributes =

        # comma-separated list of attributed to exclude
        #excludeAttributes =

        # allows creation of new LDAP accounts
        # admins can still create users via the API
        autoCreateUsers = true

        # principal cache duration
        # cacheDuration = "10 seconds"

        # interval to wait for establishing LDAP connection
        connectTimeout = "30 seconds"

        # interval to wait for receiving LDAP data
        readTimeout = "30 seconds"
        
        # ldap DNS Service Record name eg: _ldap._tcp.domain.com, Overrides url with SRV list domain controllers
        #dnsSRVName = "_ldap._tcp.domain.com"
    }

    # AD/LDAP group synchronization
    ldapGroupSync {
        # interval between runs
        interval = "1 day"

        # the number of users fetched at the time
        fetchLimit = 100

        # interval for group sync on login (interval)
        minAgeLogin = "1 hour"

        # interval for the automatic group sync (interval)
        minAgeSync = "1 day"

        # interval to delete disabled users (interval)
        # disabledAge = "30 days"
    }

    # git clone config
    git {
        # GitHub auth token to use when cloning repositories without explicitly configured authentication
        # oauth = "..."

        # use GIT's shallow clone
        shallowClone = true

        # do not execute fetch if the current HEAD is the latest commit ID
        checkAlreadyFetched = true

        # default timeout duration for any git operation
        defaultOperationTimeout = "10 minutes"

        # fetch timeout duration
        fetchTimeout = "10 minutes"

        # see GIT documentation for GIT_HTTP_LOW_SPEED_LIMIT and GIT_HTTP_LOW_SPEED_TIME
        # use with caution, can cause performance issues
        httpLowSpeedLimit = 0
        httpLowSpeedTime = "10 minutes"

        sshTimeoutRetryCount = 1
        sshTimeout = "10 minutes"
    }

    # GitHub webhook integration
    github {
        # default value, for testing only
        secret = "12345"

        # if enabled use the payload's 'sender.ldap_dn' to find the initiator
        useSenderLdapDn = true

        # save external events into the audit log
        logEvents = true

        # disable concord repos on push event with deleted ref (branch, tag)
        disableReposOnDeletedRef = false
    }

    # Ansible event processor configuration
    ansibleEvents {
        # how often the ansible event processing should run (sec)
        # if zero the task is disabled
        period = "10 seconds"

        # how many records to fetch at the time
        fetchLimit = 10000
    }

    # OneOps resource configuration
    oneops {
        # save OneOps events into the audit log
        logEvents = false
    }

    # external events (/api/v1/event/{eventName} endpoint)
    externalEvents {
        # if set the endpoint will require the specified user role
        # keys are regexes matched with eventNames, values are the required roles
        # requiredRoles = { }

        # max number of threads to use to process incoming events
        workerThreads = 5

        # save external events into the audit log
        logEvents = true
    }

    # JWT-based SSO service support
    sso {
        pfed {
            enabled = false
            priority = 0

            bearerToken {
                # enable bearer tokens
                enableBearerTokens = false

                # allow all clientIds
                allowAllClientIds = false

                # list of allowed pingfed clientids for bearer tokens
                allowedClientIds = ["clientId1", "clientId2"]
            }
        }
        authEndpointUrl = "http://auth.example.com/authorize"
        tokenEndpointUrl = "http://auth.example.com/token"
        logoutEndpointUrl = "http://auth.example.com/logout"
        redirectUrl = "http://concord.example.com/api/service/sso/redirect"
        tokenSigningKeyUrl = "http://auth.example.com/pf/JWKS"
        userInfoEndpointUrl = "https://auth.example.com/idp/userinfo.openid"
        clientId = "********"
        clientSecret = "********"
        # allows to control auto create users via sso
        autoCreateUsers = true
        # JSON as a string
        #tokenSigningKey = "{}"
        
        # enable to validate token signature
        tokenSignatureValidation = false

        # JSON as a string
        #tokenEncryptionKey = "{}"

        tokenServiceReadTimeout = "5 seconds"
        tokenServiceConnectTimeout = "500 milliseconds"
        validateNonce = false
    }

    # OpenID Connect support
    oidc {
        enabled = false
        clientId = "********"
        secret = "********"
        discoveryUri = "https://auth.example.com/.well-known/openid-configuration"

        # should point to the externally accessible FQDN and
        # match the configured callbacks in the OIDC provider
        urlBase = "http://concord.example.com"
        afterLoginUrl = "http://concord.example.com"
        afterLogoutUrl = "http://concord.example.com/#/logout/done"
        onErrorUrl = "http://concord.example.com/#/unauthorized"

        scopes = [ "openid", "profile", "email", "groups"]

        teamMapping = {
            "00000000-0000-0000-0000-000000000000" {
                source = [
                    "groups.dev.*",
                    "groups..*",
                ]
                role = "MEMBER"
            }

#             teamId2 {
#                 source = [
#                     "groups.user.*",
#                 ]
#                 role = "MEMBER"
#             }
        }

        roleMapping = {
            "concordAdmin" {
                source = [
                    "groups.admin.*"
                ]
            }
        }
    }

    # locking configuration
    locking {
        # max number of DB (advisory) locks
        maxAdvisoryLocks = 16
    }

    # QoS filter configuration
    qos {
        maxRequests = -1
        maxWait = "50 milliseconds"
        suspend = "1 second"
    }

    # noderoster plugin configuration
    noderoster {
        db {
            #url = "jdbc:postgresql://localhost:5432/postgres"
            url = ${db.url}
            url = ${?NODEROSTER_DB_URL}

            username = "postgres"
            username = ${db.appUsername}
            username = ${?NODEROSTER_DB_USERNAME}

            # password = "..."
            password = ${db.appPassword}
            password = ${?NODEROSTER_DB_PASSWORD}

            maxPoolSize = 10
        }

        events {
            # how often the ansible event processing should run
            # if zero the task is disabled
            period = "10 seconds"

            # how many records to fetch at the time
            fetchLimit = 10000

            # date/time of the first event that should be processed (ISO 8601 timestamp)
            # if partitioning is used then the value must be in the existing partition's range
            # startTimestamp = "2020-01-20T23:59:59.000Z"
        }
    }

    workerMetrics {
        # property in worker "capabilities" which is used to group up the available workers
        groupByCapabilitiesProperty = "flavor"
    }

    development {
    }

    production {
    }
}
